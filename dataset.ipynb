{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import shutil\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.ops import io_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/workspace/dataset/speech/train/audio\"\n",
    "val_list = os.path.join(data_dir, '../validation_list.txt')\n",
    "test_list = os.path.join(data_dir, '../testing_list.txt')\n",
    "\n",
    "BACKGROUND_NOISE_DIR_NAME = '_background_noise_'\n",
    "desired_samples = 16000\n",
    "\n",
    "search_path = os.path.join(data_dir, '*', '*.wav')\n",
    "\n",
    "label_words = ['silence', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "data = {'train':[], 'val':[]} \n",
    "labels = {'train':[], 'val':[]}\n",
    "\n",
    "'''wav processor'''\n",
    "with tf.name_scope('wav_loader'):\n",
    "    wav_filename = tf.placeholder(tf.string, [])\n",
    "    wav_loader = io_ops.read_file(wav_filename)\n",
    "    wav_decoder = contrib_audio.decode_wav(wav_loader, desired_channels=1, desired_samples=desired_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = []\n",
    "with open(val_list) as f:\n",
    "    val_files = f.read().splitlines()\n",
    "\n",
    "test_files = []\n",
    "with open(test_list) as f:\n",
    "    test_files = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 64721/64727 [14:16<00:00, 75.53it/s]  \n",
      "loading dataset is finished!\n"
     ]
    }
   ],
   "source": [
    "dataset_files=gfile.Glob(search_path)\n",
    "ndata = len(dataset_files)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tqdm(total=ndata, file=sys.stdout) as pbar:\n",
    "        for i in xrange(ndata):\n",
    "            wav_path = dataset_files[i]\n",
    "            p, category = os.path.split(os.path.dirname(wav_path))\n",
    "            category = category.lower()\n",
    "\n",
    "            # ignore the background noise folder\n",
    "            if category == BACKGROUND_NOISE_DIR_NAME:\n",
    "                continue\n",
    "            \n",
    "            # find the dataset split membership \n",
    "            _, fname = os.path.split(wav_path)\n",
    "            \n",
    "            f = os.path.join(category, fname)\n",
    "            if f in test_files:\n",
    "                split_cat = 'val'\n",
    "            else:\n",
    "                split_cat = 'train'\n",
    "                \n",
    "            # update the category list\n",
    "            if category not in label_words:\n",
    "                label_words.append(category)\n",
    "                \n",
    "            # decode the wav\n",
    "            wav_data = sess.run(\n",
    "                        wav_decoder,\n",
    "                        feed_dict={wav_filename: wav_path})\n",
    "            \n",
    "            # assign to the splitted dataset\n",
    "            label = word2label(category, label_words)\n",
    "            data[split_cat].append(wav_data.audio)\n",
    "            labels[split_cat].append(label)\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "print('loading dataset is finished!')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    os.makedirs( 'data' )\n",
    "    \n",
    "h5f = h5py.File(\"data/dataset.hdf5\", \"w\")\n",
    "\n",
    "h5f.create_dataset('X_train', data=data['train'])\n",
    "h5f.create_dataset('X_val', data=data['val'])\n",
    "h5f.create_dataset('Y_train', data=labels['train'])\n",
    "h5f.create_dataset('Y_val', data=labels['val'])\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silence\n",
      "yes\n",
      "no\n",
      "up\n",
      "down\n",
      "left\n",
      "right\n",
      "on\n",
      "off\n",
      "stop\n",
      "go\n",
      "bed\n",
      "happy\n",
      "sheila\n",
      "three\n",
      "eight\n",
      "cat\n",
      "dog\n",
      "five\n",
      "house\n",
      "four\n",
      "nine\n",
      "marvin\n",
      "six\n",
      "zero\n",
      "two\n",
      "wow\n",
      "bird\n",
      "tree\n",
      "one\n",
      "seven\n"
     ]
    }
   ],
   "source": [
    "f = open('data/categories.txt', 'w')\n",
    "for item in label_words:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
